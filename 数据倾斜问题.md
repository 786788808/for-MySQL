遇上数据倾斜问题，该如何优化呢？  

### 目录： 
- 什么是数据倾斜
- 数据倾斜的表现  
- 原因分析
- 解决方法

在讲这个问题前，首先得知道 map shuffle reduce key value 等等概念，大概明白整个流程是怎样的。  

## 1. 什么是数据倾斜
在并行处理的数据集中，由于数据分布不匀，某一部分的数据显著多于其它部分，从而使得该部分数据的处理速度远慢于其他部分数据的处理速度。   
有个wordcount例子，可以去看看。在默认情况下，具有相同key的数据会被放在一个reduce任务中处理，所以如果数据分布不均，就会出现“一人累死，其他人闲死”的情况。不要怀疑，这就是数据倾斜。  

## 2. 数据倾斜的表现
- 任务进度条长时间卡在 Map 100%、Reduce 99%，任务监控页面显示只剩几个 reduce 任务未完成，这部分处理的数据量比其他的总量都要大。
- 存在处理某一 reduce 任务的时长比平均时长还长

## 3. 原因分析
- key分布不均匀
- 业务数据本身的特性
- 建表时考虑不周
- 某些SQL语句本身就有数据倾斜

countdistinct、group by、join等操作，  
|  操作   | 情况  |  结果 |
|  ----  | ----  | ----  |
| join操作  | 大表连 | 单元格 |
| join操作  | 大表连大表 | 单元格 |
| Group by  | 单元格 | 单元格 |
| Count\Distinct  | 单元格 | 单元格 |

## 4. 解决方法
### 4.1 situation 1:参数调节：
使用Group by分组时，如果部分key占比较大，而最后reduce时，大家聚在一起来计算结果，就会有数据倾斜问题。进度条卡在最后一点点，始终未跑完。咋整？  
可设置：  
set hive.map.aggr = true
set hive.groupby.skewindata = true
解释：  
设置后，一个MapReduce会拆解成两个任务(MR Job)。第一个任务，Map任务的输出结果集合会随机分布到Reduce任务中，每个Reduce任务会做部分聚合操作，并输出结果。这样即使大家的key一样，但还是被分发到不同节点去处理，从而达到负载平衡的目的。第二个任务，由第一步的预处理结果，有相同key的数据会分发到同一个Reduce任务中，来个大汇总，完成最终的聚合操作。    

### 4.2 大表连接小表进行join操作
用mapjoin将小表加载到内存中，大表会去内存中读取小表，而读内存的速度是源快于读磁盘数据速度的。(小表需小于25mb，否则达不到应有的效果。)
```
select /*+ MAPJOIN(table_1) */ table_1.col_1, table_2.col_1, table_2.col_2
from table_1 inner join table_2
where table_1.col_1 = table_2.col_1;
```

