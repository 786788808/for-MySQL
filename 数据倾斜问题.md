遇上数据倾斜问题，该如何优化呢？  

### 目录： 
- 什么是数据倾斜
- 数据倾斜的表现  
- 原因分析
- 解决方法

在讲这个问题前，首先得知道 map shuffle reduce key value 等等概念，大概明白整个流程是怎样的。  

## 1. 什么是数据倾斜
在并行处理的数据集中，由于数据分布不匀，某一部分的数据显著多于其它部分，从而使得该部分数据的处理速度远慢于其他部分数据的处理速度。   
有个wordcount例子，可以去看看。在默认情况下，具有相同key的数据会被放在一个reduce任务中处理，所以如果数据分布不均，就会出现“一人累死，其他人闲死”的情况。不要怀疑，这就是数据倾斜。  

## 2. 数据倾斜的表现
- 任务进度条长时间卡在 Map 100%、Reduce 99%，任务监控页面显示只剩几个 reduce 任务未完成，这部分处理的数据量比其他的总量都要大。
- 存在处理某一 reduce 任务的时长比平均时长还长

## 3. 原因分析
- key分布不均匀
- 业务数据本身的特性
- 建表时考虑不周
- 某些SQL语句本身就有数据倾斜

count、distinct、group by、join等操作，  
|  操作   | 情况  |  结果 |
|  ----  | ----  | ----  |
| join操作  | 其中一个表较小，但是key集中 | 分发到某一个或几个Reduce上的数据远高于平均值 |
| join操作  | 大表与大表，但是分桶的判断字段0值或空值过多 | 这些空值都由一个reduce处理，灰常慢 |
| Group by  | group by 维度过小，某值的数量过多 | 处理某值的reduce灰常耗时 |
| Count\Distinct  | 某特殊值过多 | 处理此特殊值的reduce耗时 |

## 4. 解决方法
### 4.1 situation 1:参数调节：
使用Group by分组时，如果部分key占比较大，而最后reduce时，大家聚在一起来计算结果，就会有数据倾斜问题。进度条卡在最后一点点，始终未跑完。咋整？  
可设置：  
```
set hive.map.aggr = true
set hive.groupby.skewindata = true
```
解释：  
设置后，一个MapReduce会拆解成两个任务(MR Job)。第一个任务，Map任务的输出结果集合会随机分布到Reduce任务中，每个Reduce任务会做部分聚合操作，并输出结果。这样即使大家的key一样，但还是被分发到不同节点去处理，从而达到负载平衡的目的。第二个任务，由第一步的预处理结果，有相同key的数据会分发到同一个Reduce任务中，来个大汇总，完成最终的聚合操作。   

### 4.2 join操作
关于驱动表的选取，选用join key分布最均匀的表作为驱动表(驱动表，通俗的讲就是先从哪个表开始检索。不同模式会影响谁是驱动表，RBO模式与CBO模式)
做好列裁剪和filter操作，以达到两表做join的时候，数据量相对变小的效果。

### 4.3 大表连接小表进行join操作
用mapjoin将小表加载到内存中，大表会去内存中读取小表，而读内存的速度是源快于读磁盘数据速度的。(小表需小于25mb，否则达不到应有的效果。)
```
select /*+ MAPJOIN(table_1) */ table_1.col_1, table_2.col_1, table_2.col_2
from table_1 inner join table_2
where table_1.col_1 = table_2.col_1;
```
### 4.4 大表连接大表进行join操作
把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果
很经常用的一种情况，大表连大表时，关联字段存在大量空值null key
解决方法为把空值null key变成字符串加上随机数，可以把由于原先集中于一个reduce处理的数据，打散到不同的reduce上，就生成多个reduce。
```
on case when haha.id is null then concat('hive',rand()) else 
haha.id end = xixi.id
```

### 4.5 count(distinct column) 列存在大量相同特殊值
可以用‘sum … group by’代替count distinct.

